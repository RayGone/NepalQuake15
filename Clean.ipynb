{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['NepQuake15/RawNepQuake15/Nepali-Tweets-04-25.csv',\n",
       " 'NepQuake15/RawNepQuake15/Nepali-Tweets-04-26.csv',\n",
       " 'NepQuake15/RawNepQuake15/Nepali-Tweets-04-27.csv',\n",
       " 'NepQuake15/RawNepQuake15/Nepali-Tweets-04-28.csv',\n",
       " 'NepQuake15/RawNepQuake15/Nepali-Tweets-04-29.csv',\n",
       " 'NepQuake15/RawNepQuake15/Nepali-Tweets-04-30.csv',\n",
       " 'NepQuake15/RawNepQuake15/Nepali-Tweets-05-01.csv',\n",
       " 'NepQuake15/RawNepQuake15/Nepali-Tweets-05-02.csv',\n",
       " 'NepQuake15/RawNepQuake15/Nepali-Tweets-05-03.csv',\n",
       " 'NepQuake15/RawNepQuake15/Nepali-Tweets-05-04.csv',\n",
       " 'NepQuake15/RawNepQuake15/Nepali-Tweets-05-11.csv',\n",
       " 'NepQuake15/RawNepQuake15/Nepali-Tweets-05-12.csv',\n",
       " 'NepQuake15/RawNepQuake15/Nepali-Tweets-05-13.csv',\n",
       " 'NepQuake15/RawNepQuake15/Nepali-Tweets-05-14.csv',\n",
       " 'NepQuake15/RawNepQuake15/Nepali-Tweets-05-15.csv',\n",
       " 'NepQuake15/RawNepQuake15/Nepali-Tweets-05-16.csv',\n",
       " 'NepQuake15/RawNepQuake15/Nepali-Tweets-05-17.csv',\n",
       " 'NepQuake15/RawNepQuake15/Nepali-Tweets-05-18.csv',\n",
       " 'NepQuake15/RawNepQuake15/Nepali-Tweets-05-19.csv',\n",
       " 'NepQuake15/RawNepQuake15/Nepali-Tweets-05-20.csv',\n",
       " 'NepQuake15/RawNepQuake15/Nepali-Tweets-05-21.csv',\n",
       " 'NepQuake15/RawNepQuake15/Nepali-Tweets-11-30.csv',\n",
       " 'NepQuake15/RawNepQuake15/Nepali-Tweets-12-29.csv']"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = \"NepQuake15/RawNepQuake15/\"\n",
    "file_list = [os.path.join(target,x) for x in os.listdir(target)]\n",
    "file_list.sort()\n",
    "file_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### CLEANING ##### remove @usernames and external-urls\n",
    "def cleanText(pdf):\n",
    "    pdf['Text'] = pdf.apply(lambda x: re.sub('@[a-zA-Z]+','',x['Text']).strip(),axis=1) # remove @usernames\n",
    "    pdf['Text'] = pdf.apply(lambda x: re.sub('#[a-zA-Z]+','',x['Text']).strip(),axis=1) # remove hash-tag\n",
    "    pdf['Text'] = pdf.apply(lambda x: re.sub('\\w+:\\/\\/[\\w.\\/]+',' ',x['Text']).strip(),axis=1)  # remove external urls\n",
    "    pdf['Text'] = pdf.apply(lambda x: re.sub('[a-zA-Z]+','',x['Text']).strip(),axis=1)  # remove english alphabets\n",
    "    pdf['Text'] = pdf.apply(lambda x: re.sub(\"\\n+\",\"\\n\",re.sub('( +\\n +)+','\\n',x['Text'])).strip(),axis=1) # remove new line feeds and extra spaces\n",
    "    pdf['Text'] = pdf.apply(lambda x: re.sub(\"^\\s-\\s*|\\s*-\\s*$\",'',x['Text']).strip(),axis=1)\n",
    "    pdf['Text'] = pdf.apply(lambda x: re.sub(\"\\.+\",'.',x['Text']).strip(),axis=1)\n",
    "    pdf['Text'] = pdf.apply(lambda x: re.sub(\",+\",',',x['Text']).strip(),axis=1)\n",
    "    pdf['Text'] = pdf.apply(lambda x: re.sub(\"\\?+\",'\\?',x['Text']).strip(),axis=1)\n",
    "    pdf['Text'] = pdf.apply(lambda x: re.sub(\"[ред]+\",'ред',x['Text']).strip(),axis=1)\n",
    "    pdf['Text'] = pdf.apply(lambda x: re.sub(\"[\\\"]+\",'\\\"',x['Text']).strip(),axis=1)\n",
    "    return pdf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NepQuake15/RawNepQuake15/Nepali-Tweets-04-25.csv\n",
      "before (20500, 2)\n",
      "Min 1 Max 67 Avg 11.25190243902439\n",
      "after (16890, 2)\n",
      "NepQuake15/RawNepQuake15/Nepali-Tweets-04-26.csv\n",
      "before (10001, 2)\n",
      "Min 1 Max 78 Avg 12.563743625637436\n",
      "after (8318, 2)\n",
      "NepQuake15/RawNepQuake15/Nepali-Tweets-04-27.csv\n",
      "before (10001, 2)\n",
      "Min 1 Max 44 Avg 12.495350464953505\n",
      "after (8338, 2)\n",
      "NepQuake15/RawNepQuake15/Nepali-Tweets-04-28.csv\n",
      "before (6739, 2)\n",
      "Min 1 Max 43 Avg 13.11989909482119\n",
      "after (5270, 2)\n",
      "NepQuake15/RawNepQuake15/Nepali-Tweets-04-29.csv\n",
      "before (7313, 2)\n",
      "Min 1 Max 38 Avg 12.91891152741693\n",
      "after (6116, 2)\n",
      "NepQuake15/RawNepQuake15/Nepali-Tweets-04-30.csv\n",
      "before (10001, 2)\n",
      "Min 1 Max 35 Avg 12.868713128687132\n",
      "after (8633, 2)\n",
      "NepQuake15/RawNepQuake15/Nepali-Tweets-05-01.csv\n",
      "before (15001, 2)\n",
      "Min 1 Max 62 Avg 12.321845210319312\n",
      "after (12277, 2)\n",
      "NepQuake15/RawNepQuake15/Nepali-Tweets-05-02.csv\n",
      "before (15001, 2)\n",
      "Min 1 Max 38 Avg 11.969068728751417\n",
      "after (12447, 2)\n",
      "NepQuake15/RawNepQuake15/Nepali-Tweets-05-03.csv\n",
      "before (15001, 2)\n",
      "Min 1 Max 78 Avg 11.673355109659356\n",
      "after (12409, 2)\n",
      "NepQuake15/RawNepQuake15/Nepali-Tweets-05-04.csv\n",
      "before (15001, 2)\n",
      "Min 1 Max 92 Avg 11.624558362775815\n",
      "after (12614, 2)\n",
      "NepQuake15/RawNepQuake15/Nepali-Tweets-05-11.csv\n",
      "before (15001, 2)\n",
      "Min 1 Max 91 Avg 11.374441703886408\n",
      "after (12893, 2)\n",
      "NepQuake15/RawNepQuake15/Nepali-Tweets-05-12.csv\n",
      "before (15001, 2)\n",
      "Min 1 Max 60 Avg 11.76821545230318\n",
      "after (12817, 2)\n",
      "NepQuake15/RawNepQuake15/Nepali-Tweets-05-13.csv\n",
      "before (15001, 2)\n",
      "Min 1 Max 79 Avg 11.679288047463503\n",
      "after (12989, 2)\n",
      "NepQuake15/RawNepQuake15/Nepali-Tweets-05-14.csv\n",
      "before (15001, 2)\n",
      "Min 1 Max 57 Avg 11.690553963069128\n",
      "after (12966, 2)\n",
      "NepQuake15/RawNepQuake15/Nepali-Tweets-05-15.csv\n",
      "before (15001, 2)\n",
      "Min 1 Max 70 Avg 11.602759816012266\n",
      "after (12925, 2)\n",
      "NepQuake15/RawNepQuake15/Nepali-Tweets-05-16.csv\n",
      "before (15001, 2)\n",
      "Min 1 Max 44 Avg 11.346510232651157\n",
      "after (12871, 2)\n",
      "NepQuake15/RawNepQuake15/Nepali-Tweets-05-17.csv\n",
      "before (15001, 2)\n",
      "Min 1 Max 45 Avg 11.353443103793081\n",
      "after (12952, 2)\n",
      "NepQuake15/RawNepQuake15/Nepali-Tweets-05-18.csv\n",
      "before (15001, 2)\n",
      "Min 1 Max 93 Avg 11.481234584361042\n",
      "after (13121, 2)\n",
      "NepQuake15/RawNepQuake15/Nepali-Tweets-05-19.csv\n",
      "before (15001, 2)\n",
      "Min 1 Max 75 Avg 11.169788680754616\n",
      "after (12887, 2)\n",
      "NepQuake15/RawNepQuake15/Nepali-Tweets-05-20.csv\n",
      "before (15001, 2)\n",
      "Min 1 Max 55 Avg 11.484701019932004\n",
      "after (13091, 2)\n",
      "NepQuake15/RawNepQuake15/Nepali-Tweets-05-21.csv\n",
      "before (15001, 2)\n",
      "Min 1 Max 55 Avg 11.475634957669488\n",
      "after (12988, 2)\n",
      "NepQuake15/RawNepQuake15/Nepali-Tweets-11-30.csv\n",
      "before (7000, 2)\n",
      "Min 1 Max 38 Avg 11.592142857142857\n",
      "after (5856, 2)\n",
      "NepQuake15/RawNepQuake15/Nepali-Tweets-12-29.csv\n",
      "before (5000, 2)\n",
      "Min 1 Max 35 Avg 11.2926\n",
      "after (4177, 2)\n"
     ]
    }
   ],
   "source": [
    "for file in file_list:\n",
    "    print(file)\n",
    "    pdf = pd.read_csv(file)\n",
    "    print('before',pdf.shape)\n",
    "    pdf = cleanText(pdf)\n",
    "    \n",
    "    pdf.index = range(pdf.shape[0])\n",
    "    \n",
    "    ### Checking for shortest string in the dataframe\n",
    "    lengths = pdf.apply(lambda x: len(x['Text'].split(\" \")),axis=1)\n",
    "    print(\"Min\",min(lengths),\"Max\", max(lengths),\"Avg\",sum(lengths)/lengths.shape[0])\n",
    "    \n",
    "    ##### CLEANING ##### remove short sentences ----\n",
    "    indexes = pdf.apply(lambda x: len(x['Text'].split(\" \"))>=5,axis=1)\n",
    "    pdf = pdf[indexes]\n",
    "    \n",
    "    ### Drop Duplicates\n",
    "    pdf = pdf.drop_duplicates()\n",
    "    print(\"after\",pdf.shape)\n",
    "    \n",
    "    if not agg.empty:\n",
    "        agg = pd.concat([agg,pdf])\n",
    "    else:\n",
    "        agg = pdf\n",
    "    \n",
    "agg = agg.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Date\n",
       " 2015-04-25    16890\n",
       " 2015-05-18    13121\n",
       " 2015-05-20    13091\n",
       " 2015-05-13    12989\n",
       " 2015-05-21    12988\n",
       " 2015-05-14    12966\n",
       " 2015-05-17    12952\n",
       " 2015-05-15    12925\n",
       " 2015-05-11    12893\n",
       " 2015-05-19    12887\n",
       " 2015-05-16    12871\n",
       " 2015-05-12    12817\n",
       " 2015-05-04    12614\n",
       " 2015-05-02    12447\n",
       " 2015-05-03    12409\n",
       " 2015-05-01    12277\n",
       " 2015-04-30     8633\n",
       " 2015-04-27     8338\n",
       " 2015-04-26     8318\n",
       " 2015-04-29     6116\n",
       " 2015-11-30     5856\n",
       " 2015-04-28     5270\n",
       " 2015-12-29     4177\n",
       " Name: count, dtype: int64,\n",
       " (255845, 2))"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agg = agg.sort_values(by=['Date'])\n",
    "agg['Date'].value_counts(), agg.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg.to_csv(\"NepQuake15/finalized.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Date\n",
       " 2015-04-25    10454\n",
       " 2015-05-01     8451\n",
       " 2015-05-02     8256\n",
       " 2015-05-14     8247\n",
       " 2015-05-12     8189\n",
       " 2015-05-13     8141\n",
       " 2015-05-15     8139\n",
       " 2015-05-18     8112\n",
       " 2015-05-04     8084\n",
       " 2015-05-03     8083\n",
       " 2015-05-20     8044\n",
       " 2015-05-21     8003\n",
       " 2015-05-17     7973\n",
       " 2015-05-16     7963\n",
       " 2015-05-11     7943\n",
       " 2015-05-19     7745\n",
       " 2015-04-30     6121\n",
       " 2015-04-26     5779\n",
       " 2015-04-27     5742\n",
       " 2015-04-29     4337\n",
       " 2015-04-28     3791\n",
       " 2015-11-30     3687\n",
       " 2015-12-29     2583\n",
       " Name: count, dtype: int64,\n",
       " (163867, 2))"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = agg[agg.apply(lambda x: len(x['Text'].split(\" \"))>=10,axis=1)]\n",
    "test = test.sort_values(by=['Date'])\n",
    "test['Date'].value_counts(), test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.to_csv(\"NepQuake15/finalized.csv\",index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
