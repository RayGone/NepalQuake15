{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['NepQuake15/RawNepQuake15/Nepali-Tweets-04-25.csv',\n",
       " 'NepQuake15/RawNepQuake15/Nepali-Tweets-04-26.csv',\n",
       " 'NepQuake15/RawNepQuake15/Nepali-Tweets-04-27.csv',\n",
       " 'NepQuake15/RawNepQuake15/Nepali-Tweets-04-28.csv',\n",
       " 'NepQuake15/RawNepQuake15/Nepali-Tweets-04-29.csv',\n",
       " 'NepQuake15/RawNepQuake15/Nepali-Tweets-04-30.csv',\n",
       " 'NepQuake15/RawNepQuake15/Nepali-Tweets-05-01.csv',\n",
       " 'NepQuake15/RawNepQuake15/Nepali-Tweets-05-02.csv',\n",
       " 'NepQuake15/RawNepQuake15/Nepali-Tweets-05-03.csv',\n",
       " 'NepQuake15/RawNepQuake15/Nepali-Tweets-05-04.csv',\n",
       " 'NepQuake15/RawNepQuake15/Nepali-Tweets-05-11.csv',\n",
       " 'NepQuake15/RawNepQuake15/Nepali-Tweets-05-12.csv',\n",
       " 'NepQuake15/RawNepQuake15/Nepali-Tweets-05-13.csv',\n",
       " 'NepQuake15/RawNepQuake15/Nepali-Tweets-05-14.csv',\n",
       " 'NepQuake15/RawNepQuake15/Nepali-Tweets-05-15.csv',\n",
       " 'NepQuake15/RawNepQuake15/Nepali-Tweets-05-16.csv',\n",
       " 'NepQuake15/RawNepQuake15/Nepali-Tweets-05-17.csv',\n",
       " 'NepQuake15/RawNepQuake15/Nepali-Tweets-05-18.csv',\n",
       " 'NepQuake15/RawNepQuake15/Nepali-Tweets-05-19.csv',\n",
       " 'NepQuake15/RawNepQuake15/Nepali-Tweets-05-20.csv',\n",
       " 'NepQuake15/RawNepQuake15/Nepali-Tweets-05-21.csv',\n",
       " 'NepQuake15/RawNepQuake15/Nepali-Tweets-11-30.csv',\n",
       " 'NepQuake15/RawNepQuake15/Nepali-Tweets-12-29.csv']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = \"NepQuake15/RawNepQuake15/\"\n",
    "file_list = [os.path.join(target,x) for x in os.listdir(target)]\n",
    "file_list.sort()\n",
    "file_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### CLEANING ##### remove @usernames and external-urls\n",
    "def cleanText(pdf):\n",
    "    pdf['Text'] = pdf.apply(lambda x: re.sub('@[a-zA-Z]+','',x['Text']),axis=1) # remove @usernames\n",
    "    pdf['Text'] = pdf.apply(lambda x: re.sub('#[a-zA-Z]+','',x['Text']),axis=1) # remove hash-tag\n",
    "    pdf['Text'] = pdf.apply(lambda x: re.sub('\\w+:\\/\\/[\\w.\\/]+',' ',x['Text']),axis=1)  # remove external urls\n",
    "    pdf['Text'] = pdf.apply(lambda x: re.sub('[a-zA-Z]+','',x['Text']),axis=1)  # remove english alphabets\n",
    "    pdf['Text'] = pdf.apply(lambda x: re.sub(\"^\\s[-_]\\s*|\\s*-\\s*$\",'',x['Text']),axis=1)\n",
    "    pdf['Text'] = pdf.apply(lambda x: re.sub(\"\\.+\",'.',x['Text']),axis=1)\n",
    "    pdf['Text'] = pdf.apply(lambda x: re.sub(\",+\",',',x['Text']),axis=1)\n",
    "    pdf['Text'] = pdf.apply(lambda x: re.sub(\"\\?+\",'?',x['Text']),axis=1)\n",
    "    pdf['Text'] = pdf.apply(lambda x: re.sub(\"!+\",'!',x['Text']),axis=1)\n",
    "    pdf['Text'] = pdf.apply(lambda x: re.sub(\"\\*+\",'*',x['Text']),axis=1)\n",
    "    pdf['Text'] = pdf.apply(lambda x: re.sub(\"ред+\",'ред',x['Text']),axis=1)\n",
    "    pdf['Text'] = pdf.apply(lambda x: re.sub('\"+','\"',x['Text']),axis=1)\n",
    "    pdf['Text'] = pdf.apply(lambda x: re.sub(\"\\n+\",\"\\n\",re.sub('( +\\n +)+','\\n',x['Text'])),axis=1) # remove new line feeds and extra spaces\n",
    "    pdf['Text'] = pdf.apply(lambda x: re.sub(\" +\",\" \",x['Text']).strip(),axis=1) # removing spaces\n",
    "    return pdf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NepQuake15/RawNepQuake15/Nepali-Tweets-04-25.csv\n",
      "before (20500, 2)\n",
      "Min 1 Max 35 Avg 10.984878048780487\n",
      "after (16777, 2)\n",
      "NepQuake15/RawNepQuake15/Nepali-Tweets-04-26.csv\n",
      "before (10001, 2)\n",
      "Min 1 Max 35 Avg 12.28997100289971\n",
      "after (8274, 2)\n",
      "NepQuake15/RawNepQuake15/Nepali-Tweets-04-27.csv\n",
      "before (10001, 2)\n",
      "Min 1 Max 36 Avg 12.22007799220078\n",
      "after (8285, 2)\n",
      "NepQuake15/RawNepQuake15/Nepali-Tweets-04-28.csv\n",
      "before (6739, 2)\n",
      "Min 1 Max 35 Avg 12.888410743433743\n",
      "after (5242, 2)\n",
      "NepQuake15/RawNepQuake15/Nepali-Tweets-04-29.csv\n",
      "before (7313, 2)\n",
      "Min 1 Max 30 Avg 12.645972924928211\n",
      "after (6083, 2)\n",
      "NepQuake15/RawNepQuake15/Nepali-Tweets-04-30.csv\n",
      "before (10001, 2)\n",
      "Min 1 Max 33 Avg 12.574342565743425\n",
      "after (8587, 2)\n",
      "NepQuake15/RawNepQuake15/Nepali-Tweets-05-01.csv\n",
      "before (15001, 2)\n",
      "Min 1 Max 35 Avg 12.04399706686221\n",
      "after (12209, 2)\n",
      "NepQuake15/RawNepQuake15/Nepali-Tweets-05-02.csv\n",
      "before (15001, 2)\n",
      "Min 1 Max 35 Avg 11.725684954336378\n",
      "after (12378, 2)\n",
      "NepQuake15/RawNepQuake15/Nepali-Tweets-05-03.csv\n",
      "before (15001, 2)\n",
      "Min 1 Max 35 Avg 11.349776681554562\n",
      "after (12322, 2)\n",
      "NepQuake15/RawNepQuake15/Nepali-Tweets-05-04.csv\n",
      "before (15001, 2)\n",
      "Min 1 Max 35 Avg 11.33391107259516\n",
      "after (12542, 2)\n",
      "NepQuake15/RawNepQuake15/Nepali-Tweets-05-11.csv\n",
      "before (15001, 2)\n",
      "Min 1 Max 35 Avg 11.105926271581895\n",
      "after (12821, 2)\n",
      "NepQuake15/RawNepQuake15/Nepali-Tweets-05-12.csv\n",
      "before (15001, 2)\n",
      "Min 1 Max 35 Avg 11.50796613559096\n",
      "after (12747, 2)\n",
      "NepQuake15/RawNepQuake15/Nepali-Tweets-05-13.csv\n",
      "before (15001, 2)\n",
      "Min 1 Max 37 Avg 11.386974201719886\n",
      "after (12895, 2)\n",
      "NepQuake15/RawNepQuake15/Nepali-Tweets-05-14.csv\n",
      "before (15001, 2)\n",
      "Min 1 Max 35 Avg 11.426904873008466\n",
      "after (12888, 2)\n",
      "NepQuake15/RawNepQuake15/Nepali-Tweets-05-15.csv\n",
      "before (15001, 2)\n",
      "Min 1 Max 34 Avg 11.32731151256583\n",
      "after (12845, 2)\n",
      "NepQuake15/RawNepQuake15/Nepali-Tweets-05-16.csv\n",
      "before (15001, 2)\n",
      "Min 1 Max 35 Avg 11.105859609359376\n",
      "after (12788, 2)\n",
      "NepQuake15/RawNepQuake15/Nepali-Tweets-05-17.csv\n",
      "before (15001, 2)\n",
      "Min 1 Max 33 Avg 11.07552829811346\n",
      "after (12877, 2)\n",
      "NepQuake15/RawNepQuake15/Nepali-Tweets-05-18.csv\n",
      "before (15001, 2)\n",
      "Min 1 Max 35 Avg 11.213252449836677\n",
      "after (13060, 2)\n",
      "NepQuake15/RawNepQuake15/Nepali-Tweets-05-19.csv\n",
      "before (15001, 2)\n",
      "Min 1 Max 35 Avg 10.886674221718552\n",
      "after (12785, 2)\n",
      "NepQuake15/RawNepQuake15/Nepali-Tweets-05-20.csv\n",
      "before (15001, 2)\n",
      "Min 1 Max 51 Avg 11.185787614159056\n",
      "after (12999, 2)\n",
      "NepQuake15/RawNepQuake15/Nepali-Tweets-05-21.csv\n",
      "before (15001, 2)\n",
      "Min 1 Max 35 Avg 11.199253383107793\n",
      "after (12894, 2)\n",
      "NepQuake15/RawNepQuake15/Nepali-Tweets-11-30.csv\n",
      "before (7000, 2)\n",
      "Min 1 Max 35 Avg 11.237\n",
      "after (5817, 2)\n",
      "NepQuake15/RawNepQuake15/Nepali-Tweets-12-29.csv\n",
      "before (5000, 2)\n",
      "Min 1 Max 31 Avg 11.0108\n",
      "after (4141, 2)\n"
     ]
    }
   ],
   "source": [
    "for file in file_list:\n",
    "    print(file)\n",
    "    pdf = pd.read_csv(file)\n",
    "    print('before',pdf.shape)\n",
    "    pdf = cleanText(pdf)\n",
    "    \n",
    "    pdf.index = range(pdf.shape[0])\n",
    "    \n",
    "    ### Checking for shortest string in the dataframe\n",
    "    lengths = pdf.apply(lambda x: len(x['Text'].split(\" \")),axis=1)\n",
    "    print(\"Min\",min(lengths),\"Max\", max(lengths),\"Avg\",sum(lengths)/lengths.shape[0])\n",
    "    \n",
    "    ##### CLEANING ##### remove short sentences ----\n",
    "    indexes = pdf.apply(lambda x: len(x['Text'].split(\" \"))>=5,axis=1)\n",
    "    pdf = pdf[indexes]\n",
    "    \n",
    "    ### Drop Duplicates\n",
    "    pdf = pdf.drop_duplicates()\n",
    "    print(\"after\",pdf.shape)\n",
    "    \n",
    "    if not agg.empty:\n",
    "        agg = pd.concat([agg,pdf])\n",
    "    else:\n",
    "        agg = pdf\n",
    "    \n",
    "agg = agg.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Date\n",
       " 2015-04-25    16777\n",
       " 2015-05-18    13060\n",
       " 2015-05-20    12999\n",
       " 2015-05-13    12895\n",
       " 2015-05-21    12894\n",
       " 2015-05-14    12888\n",
       " 2015-05-17    12877\n",
       " 2015-05-15    12845\n",
       " 2015-05-11    12821\n",
       " 2015-05-16    12788\n",
       " 2015-05-19    12785\n",
       " 2015-05-12    12747\n",
       " 2015-05-04    12542\n",
       " 2015-05-02    12378\n",
       " 2015-05-03    12322\n",
       " 2015-05-01    12209\n",
       " 2015-04-30     8587\n",
       " 2015-04-27     8285\n",
       " 2015-04-26     8274\n",
       " 2015-04-29     6083\n",
       " 2015-11-30     5817\n",
       " 2015-04-28     5242\n",
       " 2015-12-29     4141\n",
       " Name: count, dtype: int64,\n",
       " (254256, 2))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agg = agg.sort_values(by=['Date'])\n",
    "agg['Date'].value_counts(), agg.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg.to_csv(\"NepQuake15/finalized.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Date\n",
       " 2015-04-25    10132\n",
       " 2015-05-01     8201\n",
       " 2015-05-02     8067\n",
       " 2015-05-14     8021\n",
       " 2015-05-12     7938\n",
       " 2015-05-15     7907\n",
       " 2015-05-13     7907\n",
       " 2015-05-18     7848\n",
       " 2015-05-03     7806\n",
       " 2015-05-04     7788\n",
       " 2015-05-20     7776\n",
       " 2015-05-21     7749\n",
       " 2015-05-16     7736\n",
       " 2015-05-17     7724\n",
       " 2015-05-11     7688\n",
       " 2015-05-19     7469\n",
       " 2015-04-30     5946\n",
       " 2015-04-26     5627\n",
       " 2015-04-27     5607\n",
       " 2015-04-29     4222\n",
       " 2015-04-28     3714\n",
       " 2015-11-30     3555\n",
       " 2015-12-29     2485\n",
       " Name: count, dtype: int64,\n",
       " (158913, 2))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = agg[agg.apply(lambda x: len(x['Text'].split(\" \"))>=10,axis=1)]\n",
    "test = test.sort_values(by=['Date'])\n",
    "test['Date'].value_counts(), test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.to_csv(\"NepQuake15/finalized.csv\",index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
